[
  {
    "objectID": "base_ecol/cheat.html#exponents-and-logarithms",
    "href": "base_ecol/cheat.html#exponents-and-logarithms",
    "title": "Mathematics Cheat Sheet for Quantitative Ecology",
    "section": "Exponents and Logarithms",
    "text": "Exponents and Logarithms\nProperties of Exponentials\n\\[\nx^ax^b = x^{a+b} \\\\\n\\dfrac{x^a}{x^b} = x^{a-b} \\\\\nx^a = e^{a log(x)} \\\\\n(x^{a})^b = x^{ab} \\\\\nx^{-a} = \\dfrac{1}{x^a}\n\\]"
  },
  {
    "objectID": "base_ecol/cheat.html#exponents-and-logarithms-1",
    "href": "base_ecol/cheat.html#exponents-and-logarithms-1",
    "title": "Mathematics Cheat Sheet for Quantitative Ecology",
    "section": "Exponents and Logarithms",
    "text": "Exponents and Logarithms\nProperties of Logarithms\n\\[\nlog(x^a) = a log(x) \\\\\nlog(ab) = log(a) + log(b) \\\\\nlog\\left(\\dfrac{a}{b}\\right) = log(a) - log(b)\n\\]"
  },
  {
    "objectID": "base_ecol/cheat.html#calculus---derivatives",
    "href": "base_ecol/cheat.html#calculus---derivatives",
    "title": "Mathematics Cheat Sheet for Quantitative Ecology",
    "section": "Calculus - Derivatives",
    "text": "Calculus - Derivatives"
  },
  {
    "objectID": "base_ecol/cheat.html#calculus---integrals",
    "href": "base_ecol/cheat.html#calculus---integrals",
    "title": "Mathematics Cheat Sheet for Quantitative Ecology",
    "section": "Calculus - Integrals",
    "text": "Calculus - Integrals"
  },
  {
    "objectID": "base_ecol/cheat.html#linear-algebra---matrix-math",
    "href": "base_ecol/cheat.html#linear-algebra---matrix-math",
    "title": "Mathematics Cheat Sheet for Quantitative Ecology",
    "section": "Linear Algebra - Matrix Math",
    "text": "Linear Algebra - Matrix Math"
  },
  {
    "objectID": "base_ecol/cheat.html#linear-algebra---eigenvalues-and-eigenvectors",
    "href": "base_ecol/cheat.html#linear-algebra---eigenvalues-and-eigenvectors",
    "title": "Mathematics Cheat Sheet for Quantitative Ecology",
    "section": "Linear Algebra - Eigenvalues and Eigenvectors",
    "text": "Linear Algebra - Eigenvalues and Eigenvectors"
  },
  {
    "objectID": "stock_assess/Likelihoods.html",
    "href": "stock_assess/Likelihoods.html",
    "title": "Likelihoods",
    "section": "",
    "text": "The main types of data integrated within stock assesments include annual removals (total catch from a fishery), abundance indices, and distributions of length and/or ages in the catches (i.e., composition data). Abundance indices and composition data often derive from fisheries and research surveys (i.e., fishery-dependent and fishery independent).\nThese data provide critical information on\n\nrelative year-class strength\nmortality\nselectivity"
  },
  {
    "objectID": "stock_assess/Likelihoods.html#likelihoods",
    "href": "stock_assess/Likelihoods.html#likelihoods",
    "title": "Likelihoods",
    "section": "",
    "text": "The main types of data integrated within stock assesments include annual removals (total catch from a fishery), abundance indices, and distributions of length and/or ages in the catches (i.e., composition data). Abundance indices and composition data often derive from fisheries and research surveys (i.e., fishery-dependent and fishery independent).\nThese data provide critical information on\n\nrelative year-class strength\nmortality\nselectivity"
  },
  {
    "objectID": "stock_assess/Likelihoods.html#age-composition",
    "href": "stock_assess/Likelihoods.html#age-composition",
    "title": "Likelihoods",
    "section": "Age composition",
    "text": "Age composition\nAge-based stock assessments can be modeled into two classes depending on the data\n\nNumbers-at-age\nProportions-at-age\n\n\nUnivariate numbers-at-age\n\nLognormal distribution\n\n\\(x &gt; 0\\) is the observed catch (or survey index) at a given age\n\\(\\mu &gt; 0\\) is the calculated catch at that age (or survey index)\n\\(\\sigma &gt; 0\\) is a scale parameter\n\n\\[\nf(x ; \\mu, \\sigma)=\\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} \\exp \\left\\{\\frac{-[\\log (x)-\\log (\\mu)]^{2}}{2 \\sigma^{2}}\\right\\} x^{-1}\n\\]\n\nmean: \\(\\mu exp({\\sigma^2}/2)\\)\nmedian: \\(\\mu\\)\nvariance: \\((exp(\\sigma^2)-1) exp[2log(\\mu) + \\sigma^2]\\)\n\n\n\nGamma distribution\n\n\\(x &gt; 0\\) is the observed catch (or survey index) at a given age\n\\(\\mu &gt; 0\\) is the calculated catch at that age (or survey index)\n\\(\\sigma &gt; 0\\) is a scale parameter\n\n\\[\nf(x ; \\mu, \\sigma)=\\frac{1}{\\Gamma(\\sigma)\\left(\\frac{\\mu}{\\sigma}\\right)^{\\sigma}} x^{\\sigma-1} \\exp (-x \\sigma / \\mu)\n\\]\n\nmean: \\(\\mu\\)\nvariance: \\(\\mu^2/\\sigma\\)\n\n\n\nGeneralized gamma distribution\n\n\\(x &gt; 0\\) is the observed catch (or survey index) at a given age\n\\(\\mu &gt; 0\\) is the calculated catch at that age (or survey index)\n\\(\\sigma &gt; 0\\) is a scale parameter\n\\(\\tau \\in \\mathbb{R}\\) is a shape parameter\n\n\\[\nf_{3}(x ; \\mu, \\sigma, \\tau)=\\left\\{\\begin{array}{ll}\n\\left.|\\tau|\\left(\\tau^{-2}\\right)^{\\tau^{-2}} \\exp \\left(\\tau^{-2}\\left\\{\\tau \\frac{\\log (x)-\\log (\\mu)}{\\sigma}-\\exp \\left[\\tau \\frac{\\log (x)-\\log (\\mu)}{\\sigma}\\right]\\right\\}\\right) \\right\\rvert\\,\\left[\\sigma x \\Gamma\\left(\\tau^{-2}\\right)\\right], & \\tau \\neq 0 \\\\\n(2 \\pi)^{-1 / 2} \\exp \\left\\{-\\frac{[\\log (x)-\\log (\\mu)]^{2}}{2 \\sigma^{2}}\\right\\}(\\sigma x)^{-1}, & \\tau=0\n\\end{array}\\right\n\\]\n\n\nNormal distribution\n\n\nTruncated normal distribution\n\n\nStudent’s t distribution\n\n\n\nMultivariate numbers-at-age\n\nMultivariate lognormal\n\n\n\nProportions-at-age\n\nMultinomial\n\n\nAdditive logistic-normal distribution\n\n\nMultiplicative logistic-normal distribution\n\n\nDirichlet distribution\n\n\n\nSummary of age composition likelihoods\n\n\n\n\n\n\n\n\n\n\n\nDistribution\nClass\nAllows Zeros\nBaranov\nNumber of estimated observation parameters\nEstimated correlation parameter?\n\n\n\n\nLognormal\nunivariate numbers-at-age\nno\nmedian\n1 per age per fleet\nno\n\n\nGamma\nunivariate numbers-at-age\nsome\nmean\n1 per age per fleet\nno\n\n\nGeneralized gamma\nunivariate numbers-at-age\nsome\nlocation\n2 per age per fleet\nno\n\n\nNormal\nunivariate numbers-at-age\nyes\nmean\n1 per age per fleet\nno\n\n\nLeft truncated normal\nunivariate numbers-at-age\nyes\nlocation\n1 per age per fleet\nno\n\n\nlog-Student’s t\nunivariate numbers-at-age\nno\nlocation\n2 per age per fleet\nno\n\n\nMultivariate lognormal\nmultivariate numbers-at-age\nno\nmedian\n1 per age per fleet and 1 additional per fleet\nyes\n\n\nMultinomial\nproportions-at-age total numbers/total mass\n\n\n\n\n\n\nAdditive logistic normal\nproportions-at-age total numbers/total mass\nno\nlocation\n1 per age per fleet and 1 additional per fleet\nyes\n\n\nMultiplicative logistic normal\nproportions-at-age total numbers/total mass\nno\nlocation\n1 per age per fleet and 1 additional per fleet\nyes\n\n\nDirichlet\nproportions-at-age total numbers/total mass\nno\nmean\n1 per fleet\nno\n\n\n\n** table based on Table 1 in Albertsen et al., 2017"
  },
  {
    "objectID": "stock_assess/equil_recruit.html",
    "href": "stock_assess/equil_recruit.html",
    "title": "Equilibrium Recruitment",
    "section": "",
    "text": "\\(R_0\\): virgin, unfished recruitment\n\\(\\Phi_0\\): virgin, unfished spawning biomass per recruit\n\\(S_{0}\\): virgin unfished spawning biomass\n\\(\\Phi_F\\) biomass per recruit at \\(F \\neq 0\\)\n\\(YPR_F\\): yield per recruit at \\(F \\neq 0\\)\n\\(CR\\): compensation ratio\n\\(h\\): steepness\n\\(SRR\\): stock-recruitment relationship"
  },
  {
    "objectID": "stock_assess/equil_recruit.html#definitions",
    "href": "stock_assess/equil_recruit.html#definitions",
    "title": "Equilibrium Recruitment",
    "section": "",
    "text": "\\(R_0\\): virgin, unfished recruitment\n\\(\\Phi_0\\): virgin, unfished spawning biomass per recruit\n\\(S_{0}\\): virgin unfished spawning biomass\n\\(\\Phi_F\\) biomass per recruit at \\(F \\neq 0\\)\n\\(YPR_F\\): yield per recruit at \\(F \\neq 0\\)\n\\(CR\\): compensation ratio\n\\(h\\): steepness\n\\(SRR\\): stock-recruitment relationship"
  },
  {
    "objectID": "stock_assess/equil_recruit.html#ypr-quantities-at-various-fishing-mortalities",
    "href": "stock_assess/equil_recruit.html#ypr-quantities-at-various-fishing-mortalities",
    "title": "Equilibrium Recruitment",
    "section": "YPR quantities at various fishing mortalities",
    "text": "YPR quantities at various fishing mortalities\nFind \\(SBPR\\) and \\(YPR\\) at the \\(F\\) value of interest and calculate these values when \\(F = 0\\). This will vary depending on your model:\n\\[\nYPR=\\Sigma_{a} F s_{a} N_{a} w_{a}\n\\]\n\n\\(N_a\\) is a proportional expected numbers-at-age\n\\(w_a\\) is the expected weight-at-age\n\\(s_a\\) is fishery selectivity"
  },
  {
    "objectID": "stock_assess/equil_recruit.html#ypr-quantities-at-various-fishing-mortalities-1",
    "href": "stock_assess/equil_recruit.html#ypr-quantities-at-various-fishing-mortalities-1",
    "title": "Equilibrium Recruitment",
    "section": "YPR quantities at various fishing mortalities",
    "text": "YPR quantities at various fishing mortalities\n\\[\nSBPR = \\sum_a E_a N_a w_a\n\\]\n\n\\(E_a\\): some measure of population’s fecundity at age\nthe resulting \\(SBPR\\) is going to vary with \\(F\\) because \\(N_a\\) will decline faster when \\(F\\) is greater than zero."
  },
  {
    "objectID": "stock_assess/equil_recruit.html#beverton-holt---srr-in-terms-of-sbpr",
    "href": "stock_assess/equil_recruit.html#beverton-holt---srr-in-terms-of-sbpr",
    "title": "Equilibrium Recruitment",
    "section": "Beverton-Holt - SRR in terms of SBPR",
    "text": "Beverton-Holt - SRR in terms of SBPR"
  },
  {
    "objectID": "stock_assess/equil_recruit.html#beverton-holt-function-in-terms-of-steepness",
    "href": "stock_assess/equil_recruit.html#beverton-holt-function-in-terms-of-steepness",
    "title": "Equilibrium Recruitment",
    "section": "Beverton-Holt function in terms of steepness",
    "text": "Beverton-Holt function in terms of steepness\nsteepness as a function of proportion \\(p\\) of unfished spawning stock size \\(S_0\\) and \\(\\alpha\\) and the unexploited spawning biomass per recruit \\(\\Phi_0\\)\n\\[\nh(p) = \\dfrac{R(S= pS_0)}{R(S=S_0)} = p \\dfrac{1+\\beta S_0}{1_p \\beta S_0} = p \\dfrac{1 + \\beta \\Phi_0 R_0}{1 + p \\beta \\Phi_0 R_0}\n\\]"
  },
  {
    "objectID": "stock_assess/equil_recruit.html#beverton-holt-function-in-terms-of-steepness-1",
    "href": "stock_assess/equil_recruit.html#beverton-holt-function-in-terms-of-steepness-1",
    "title": "Equilibrium Recruitment",
    "section": "Beverton-Holt function in terms of steepness",
    "text": "Beverton-Holt function in terms of steepness\nTo complete the steepness transformation of the SRR, we must define unexploited recruitment and unexploited spawning biomass per recruit"
  },
  {
    "objectID": "stock_assess/equil_recruit.html#ricker-function-in-terms-of-steepness",
    "href": "stock_assess/equil_recruit.html#ricker-function-in-terms-of-steepness",
    "title": "Equilibrium Recruitment",
    "section": "Ricker function in terms of steepness",
    "text": "Ricker function in terms of steepness\nsteepness as a function of proportion \\(p\\) of unfished spawning stock size \\(S_0\\) and \\(\\alpha\\) and the unexploited spawning biomass per recruit \\(\\Phi_0\\)"
  },
  {
    "objectID": "stock_assess/equil_recruit.html#conversion-to-compensation-ratio",
    "href": "stock_assess/equil_recruit.html#conversion-to-compensation-ratio",
    "title": "Equilibrium Recruitment",
    "section": "Conversion to compensation ratio",
    "text": "Conversion to compensation ratio"
  },
  {
    "objectID": "stock_assess/recruitment_basics.html",
    "href": "stock_assess/recruitment_basics.html",
    "title": "Understanding Recruitment",
    "section": "",
    "text": "Notes based on:"
  },
  {
    "objectID": "stock_assess/recruitment_basics.html#recruitment",
    "href": "stock_assess/recruitment_basics.html#recruitment",
    "title": "Understanding Recruitment",
    "section": "Recruitment",
    "text": "Recruitment\nRecruitment refers to the act of young fish transitioning between two stages of life. What is important here is what happens before and after this transition, which is when the rate at which fish die from natural mortality does not depend on the density of fish (i.e., density-independent mortality). This means that survival of an individual fish is not influenced by the number of other fish within the population. In the before stage, fish begin life as a fertilized egg that hatches into a larval fish. Mortality for egg and larval stages are considered density-independent because environmentally-driven variability in mortality tends to be strongest in this stage.\nEventually, they settle into habitat or aggregrate into schools. This settlement phase is where most scientists think mortality begins to be density-dependent (Walters and Juanes, 1993). During this transitional period (i.e., the recruitment period), the natural mortality does depend on the density of fish (i.e., density-dependent mortality). This means that mortaltiy will decrease (and survival will increase) with decreasing density of fish. This is based on the idea that resources during this period are limited and decreased densities reduce competition for food, space, and refuge (Walters and Juanes 1993). Fish that survive the density-dependent mortality recruitment stage are referred to as recruits. As fish grow in size through the recruitment period, they become less vulnerable to predators and grow large enough that density-dependent mortality ceases. This is the after stage.\nIn the context of stock assessment, we need to estimate recruitment that reproduce the observed catch and match survey trends and age composition. We also need to forecast recruitment to provide advice on future stock trajectory and catch advice."
  },
  {
    "objectID": "stock_assess/recruitment_basics.html#deep-dive-into-origin-of-stock-recruitment-relationship",
    "href": "stock_assess/recruitment_basics.html#deep-dive-into-origin-of-stock-recruitment-relationship",
    "title": "Understanding Recruitment",
    "section": "Deep dive into origin of stock-recruitment relationship",
    "text": "Deep dive into origin of stock-recruitment relationship\nStock-recruitment functions describe the production of new recruits to a fish population and the dependence of that production on the spawning component of the population. It captures the effects of environmental variability, however it does not model the underlying biological processes. You cannot have recruitment without spawners (Myers and Barrowman, 1996) and recruitment cannot increase without bounds. Stock-recruitment functions pass through the origin and exhibit some form of density dependence.\nBeverton and Holt (1957) found that spawning stock is generally a poor predictor of recruitment (i.e., recruitment being independent of abundance) except at relatively low stock sizes. However, this does not mean there is no stock-recruit relationship. There is still a link between spawning biomass and recruits (note, not a predictor); the number of eggs spawned depends on the mature component of the stock. The average survival rate from egg to recruitment decreases with increasing spawning stock size. When there is low amount of eggs, the survival rate is greater. This is all as a result of density dependent and competition where is there is a decrease in juvenile survival with increasing abundance. This refers to one of the most commonly assumed forms of the stock-recruitment function: the Beverton-Holt (Beverton and Holt 1957).In the Beverton-Holt function, recruitment is a function of spawning biomass \\(S\\) that increases towards an asymptotic value with increased spawning biomass. Density dependence pertains to coexisting pre-recruits (e.g., through competition).\nAnother common recruitment function is the Ricker (1954). For the Ricker function, recruitment is an asymmetric dome-shaped function of spawning biomass \\(S\\). Density dependence pertains to spawning biomass (e.g., through cannibalism, competition, predation).\n\nDerivations\nIn the original derivations, the units of spawning stock was eggs. The Beverton-Holt is derived as:\n\\[\nR_{t + a_r} = \\dfrac{E_t e^{-M_I a_r}}{1 + \\dfrac{M_D}{M_I} (1-e^{-M_I a_r}) E_t}\n\\]\n\n\\(a_r\\): age of recruitment\n\\(E_t\\): number of eggs spawned at time t\n\\(M_D\\): instantaneous density-dependent mortality rate\n\\(M_I\\): instantaneous density-independent mortality rate\n\nFor Ricker, the mature stock is expressed in terms of the initial number of eggs laid (Ricker 1954). Thus, the function is:\n\\[\nR_{t+a_r} = E_t e^{-(M_I + M_E E_t)a_r}\n\\]\n\n\\(M_E\\): represent density-dependent mortality that is proportional to the initial number of eggs \\(E_t\\)\n\nIt is more commeon to reparameterize these functions in terms of spawning biomass because the number of eggs produced is usually unknown. This is how it’s done:\n\\[\nE_t = \\sum_a f_{t,a} m_{t,a} w_{t,a} N_{t,a}\n\\]\n\n\\(f_{t,a}\\): relative feduncity (eggs per unit mass)\n\\(m_{t,a}\\): maturity at age\n\\(w_{t,a}\\): weight at age\n\\(N_{t,a}\\): abundance at age\n\nRelative fecundity is assumed to be invariant to mass or age, so that:\n\\[\nE_t = f \\sum_a m_{t,a} w_{t,a} N_{t,a} = f S_t\n\\]\nThis allows total egg production to be proportional to spawning biomass \\(S_t\\).\nThis transform the Beverton-Holt function to:\n\\[\nR_{t+a_r} = \\dfrac{\\alpha S_t}{1 + \\beta S_t}\n\\]\nwhere\n\\[\n\\alpha = f e^{-M_I a_r}\n\\]\nand\n\\[\n\\beta = f \\dfrac{M_D}{M_I} (1-e^{-M_I a_r}) = \\dfrac{M_D}{M_I}(f-\\alpha)\n\\]\n\\(\\alpha\\) is proportional to the fraction surviving the pre-recruit stage from density-independent mortality, and it is the rate of recruitment when \\(S_t=0\\). In other words, \\(\\alpha\\) is the maximum average survival rate absent of density effects. \\(\\beta\\) is a “scaling” parameter that includes density-dependent and -independent mortality components. Note that \\(\\beta\\) is a function of \\(\\alpha\\).\nRicker function of spawning biomass is:\n\\[\nR_{t+a_r} = \\alpha S_t e^{-\\beta_E S_t}\n\\]\nwhere\n\\[\n\\alpha = f e^{-M_I a_r}\n\\]\nand\n\\[\n\\beta_E = f M_E a_r\n\\]\nThe \\(\\alpha\\) and \\(\\beta_E\\) terms are independent, unlike in the Beverton-Holt (aside from them being a function of the age at recruitment and relative fecundity)."
  },
  {
    "objectID": "stock_assess/recruitment_basics.html#what-is-steepness",
    "href": "stock_assess/recruitment_basics.html#what-is-steepness",
    "title": "Understanding Recruitment",
    "section": "What is steepness?",
    "text": "What is steepness?\n“the fraction of recruitment from a virgin population obtained when the spawner are at 20% of the virgin level”"
  },
  {
    "objectID": "stock_assess/recruitment_basics.html#references",
    "href": "stock_assess/recruitment_basics.html#references",
    "title": "Understanding Recruitment",
    "section": "References",
    "text": "References\nBeverton, R. J. H., & Holt, S. J. (1957). On the dynamics of exploited fish populations. Chapman and Hall, London, Fish and Fisheries Series No. 11, fascimile reprint 1993.\nMyers, R. A., & Barrowman, N. J. (1996). Is fish recruitment related to spawner abundance? Fishery Bulletin, 94(4), 707–724.\nRicker, W. E. (1975). Computation and interpretation of biological statistics of fish populations. Bulletin of the Fisheries Research Board of Canada, Number 119, 382 p.\nWalters, C. J., & Juanes, F. (1993). Recruitment limitation as a consequence of natural selection for use of restricted feeding habitats and predation risk taking by juvenile fishes. Canadian Journal of Fisheries and Aquatic Sciences, 50(10), 2058-2070."
  },
  {
    "objectID": "num_meths/Newton.html",
    "href": "num_meths/Newton.html",
    "title": "Newton-Raphson Method",
    "section": "",
    "text": "Newton-Raphson method is an iterative numerical technique used to finding approximate solutions to equations.\nThis is used to solve equations of the form \\(f(x) = 0\\) where \\(f(x)\\) is a real-valued function of a real variable.\nGiven an initial guess (\\(x_0\\)), the method iteratively refines this guess to get closer and closer to a root of the equation."
  },
  {
    "objectID": "num_meths/Newton.html#newton-raphson-description",
    "href": "num_meths/Newton.html#newton-raphson-description",
    "title": "Newton-Raphson Method",
    "section": "",
    "text": "Newton-Raphson method is an iterative numerical technique used to finding approximate solutions to equations.\nThis is used to solve equations of the form \\(f(x) = 0\\) where \\(f(x)\\) is a real-valued function of a real variable.\nGiven an initial guess (\\(x_0\\)), the method iteratively refines this guess to get closer and closer to a root of the equation."
  },
  {
    "objectID": "num_meths/Newton.html#formula",
    "href": "num_meths/Newton.html#formula",
    "title": "Newton-Raphson Method",
    "section": "Formula",
    "text": "Formula\n\nThe core formula for the Newton-Raphson methods is: \\[\nx_{n+1} = x_n-\\dfrac{f(x_n)}{(f^\\prime x_n)}\n\\]\n\nwhere:\n\n\\(x_{n+1}\\) is the next approximation of the root\n\\(x_n\\) is the current approximation of the root\n\\(f(x_n)\\) is the value of the function at \\(x_n\\)\n\\(f^\\prime x_n\\) is the derivative (slope) of the function at \\(x_n\\)"
  },
  {
    "objectID": "num_meths/num_meths.html",
    "href": "num_meths/num_meths.html",
    "title": "Numerical Methods",
    "section": "",
    "text": "Topic\nSub-topic\nNotes\nCode\n\n\n\n\n\n\nNewton-Raphson Method\n📖\n🖥️\n\n\n\nModel Diagnostics\nTMB Model Convergence\n📖\n🖥️\n\n\n\n\nModel validation\n📖\n🖥️"
  },
  {
    "objectID": "num_meths/TMB_convergence.html",
    "href": "num_meths/TMB_convergence.html",
    "title": "TMB Model Convergence",
    "section": "",
    "text": "This example is using RTMB, which uses similar R functions as TMB.\nSay you construct an objective function called obj. Here, f is the model function and par contains a list of initial parameter values.\npar &lt;- list(x = 1,\n            y = 2,\n            sd = 0.5)\nf &lt;- function(par) {\n    return(jnll)\n}\nobj &lt;- MakeADFun(func = f, parameters = par)\nIf you’re creating a new function, you should check if the model will run before running an optmizer. If there are no errors in the code, no warning messages will pop up. However, this doesn’t always mean that the model will function. This is because the model formulation or parameterization may be incorrect. You can check this by checking if a likelihood and gradient function will give values:\n# check likelihood function\nobj$fn()\n# check gradient function\nobj$gr()\nIf the model is estimable, it will calculate a likelihood based on the initial parameters. Each parameter should also provide a gradient. If the gradient of a parameter = 0, this means that the model will not estimate that parameter or the parameter is not being used in the model.\nIf the checks on obj are successful, then you can run it with an optimizer. Here is an example using nlminb and opt is the output:\nopt &lt;- nlminb(obj$par, obj$gr, obj$gr)\nWarning messages of “NA/NaN function evaluation” may pop out, but this does not always mean the model is not converged. This means that within an iteration, a parameter estimate has a NA/NaN. You will need to check this. You may need to change the parameterization (e.g., transform parameter to log space). You can check the parameter estimation at each evaluation by running obj$env$tracepar &lt;- TRUE before running the optimizer.\nNote: This will print every parameter at each evaluation and take longer.\nobj &lt;- MakeADFun(func = f, parameters = par)\nobj$env$tracepar &lt;- TRUE\nopt &lt;- nlminb(obj$par, obj$gr, obj$gr)"
  },
  {
    "objectID": "num_meths/TMB_convergence.html#convergence-criteria",
    "href": "num_meths/TMB_convergence.html#convergence-criteria",
    "title": "TMB Model Convergence",
    "section": "Convergence criteria",
    "text": "Convergence criteria\nThe model is considered converged if:\n\nConvergence message = 0 and have good convergence message(s).\nMaximum gradient &lt; 1e-3.\nHessian is invertible.\nParameters are identifable.\nStandard errors for model estimates are reasonable.\nFit to data\n\nFor the model to be considered “converged”, it is crucial to follow each test step consecutively. If at any point a step/test fails, please refrain from proceeding to the next step or test."
  },
  {
    "objectID": "num_meths/TMB_convergence.html#convergence-messages",
    "href": "num_meths/TMB_convergence.html#convergence-messages",
    "title": "TMB Model Convergence",
    "section": "1. Convergence messages",
    "text": "1. Convergence messages\n\n# look if the model is converged and well estimated\nopt$convergence\nopt$message\n\nIf the model is considered converged, opt$convergence = 0. If the model did not converge, opt$convergence = 1. There can be several reasons why the model failed to converge:\n\nsingular convergence: model is likely overparameterized (too complex for data).\nfalse convergence: likelihood may be discontinuous\nrelative convergence but Hessian not positive definite = singularity\n\nSome of these convergence issues can be solved by fixing some parameters. Check which parameters are not estimating well. It is recommended to fix one parameter at a time.\nNote: the parameter with the highest gradient isn’t always the one you should fix first."
  },
  {
    "objectID": "num_meths/TMB_convergence.html#gradients",
    "href": "num_meths/TMB_convergence.html#gradients",
    "title": "TMB Model Convergence",
    "section": "2. Gradients",
    "text": "2. Gradients\nGradient is the vector of derivatives of the negative log likelihood function with respect to each parameter.\n\nprovides information about the direction and magnitude of the steepest increase in the negative log likelihood function.\nIn maximum likelihood, you use gradient ascent\n\nupdate the parameter estimates in the direction of the gradient to move towards the maximum likelihood values.\noptimizer adjusts parameter values iteratively based on gradient information until convergence is reached and a maximum likelihood estimate is obtained\n\n\nThe typical threshold for the gradient is 1e-3, meaning that a converged model will have a maximum gradient &lt; 1e-3. If the absolute of the maximum gradient is too high (&gt; 1e-3), it indicates that parameter values are far from the optimal values that maximize the objective function. You can check the maximum gradient:\n\n# grab gradients of each parameter\nfinal_gradient &lt;- obj$gr(opt$par)\n# maximum gradient below 1e-3?\nmax(abs(final_gradient))"
  },
  {
    "objectID": "num_meths/TMB_convergence.html#invertible-hessian",
    "href": "num_meths/TMB_convergence.html#invertible-hessian",
    "title": "TMB Model Convergence",
    "section": "3. Invertible Hessian",
    "text": "3. Invertible Hessian\nThe Hessian will not be invertible if the negative log likelihood is not a true maximum. Inverting the negative Hessian gives us the covariance matrix, which is why this needs to be invertible. This usually occurs when the model is mis-specified, which could mean either the parameters are too confounded or overparameterized (i.e., too complex for data). RTMB will warn about uninvertible Hessians with NaNs in the gradient or estimation of standard deviations for parameter estimates.\nYou can obtain the Hessian matrix using:\n\n# no random effects\nfixed_obj &lt;- obj$env$last.par.best\n# remove parameters that are random effects\nif(length(obj$env$random &gt; 0)) {\n    fixed_obj &lt;- obj$env$last.par.best[-c(obj$env$random)]\n}\n# Hessian\nHess &lt;- optimHess(par = fixed_obj, fn = obj$fn, gr = obj$gr)\n# are there any NaNs?\nis.nan(max(Hess))\n\nIf there are NaNs, you will need to check if the parameters are identifiable."
  },
  {
    "objectID": "num_meths/TMB_convergence.html#identifiable-parameters",
    "href": "num_meths/TMB_convergence.html#identifiable-parameters",
    "title": "TMB Model Convergence",
    "section": "4. Identifiable parameters",
    "text": "4. Identifiable parameters\nParameters are considered identifiable if the model can uniquely determine the values of the parameters from the observed data. A model is identifiable if different sets of parameter values lead to different probability distributions for the observed data.\nThis is evaluated using eigenvalues. Eigenvalues are related to identifiability through their connection to the rank of matrices, especially the design matrix in linear models. The design matrix relates the observations to the model parameters. If the design matrix has full rank, all eigenvalues are non-zero and it implies that each parameter is uniquely estimable from the data.\nIf parameters are not identifiable, the hessian (and standard error) cannot be estimated for that parameter and the model has failed to converge. The model will require adjustments or constraints to ensure meaningful parameter estimates. Sometimes, fixing the non-identifiable parameter improves the model run.\n\neigen_test &lt;- eigen(Hess)\nwhichbad_eigen &lt;- which(eigen_test$values &lt; sqrt(.Machine$double.eps))\n# this will provide a data frame with parameter estimates\n# which tell if parameters are identifiable (\"Ok\") or not (\"Bad\")\nif(length(eigen_test$vectors[,whichbad_eigen]) &gt; 0) {\n    rowmax = apply(as.matrix(eigen_test$vectors[, whichbag_eigen]),\n            MARGIN = 1, FUN = function(x){ max(abs(x)) })\n    eigen_mat &lt;- data.frame(\n        \"Parameters\" = names(obj$par),\n        \"MLE\" = fixed_obj,\n        \"Parameter_check\" = ifelse(rowmax &lt; 0.001, \"Bad\", \"Ok\")\n    )\n}\n\nWarning: This check should only be conducted if the gradients meet the threshold."
  },
  {
    "objectID": "num_meths/TMB_convergence.html#standard-errors",
    "href": "num_meths/TMB_convergence.html#standard-errors",
    "title": "TMB Model Convergence",
    "section": "5. Standard errors",
    "text": "5. Standard errors\nIf the standard errors for the parameter estimates are high, it suggests that model is not fully converged. This can mean:\n\nLow precision: there could be a wide range of plausible values for the parameters\nLack of stability in estimation\nPotential identifiability issues\nOverfitting: model may be too complex and is capturing noise in the data rather than true underlying patterns\n\nThis does not stop the model run, but considerations should be made to check the parameter estimates and rerun the model if the standard errors are unreasonable.\n\nsdrep &lt;- sdreport(obj)\nsummary(sdrep)"
  },
  {
    "objectID": "num_meths/TMB_convergence.html#fit-to-data",
    "href": "num_meths/TMB_convergence.html#fit-to-data",
    "title": "TMB Model Convergence",
    "section": "6. Fit to data",
    "text": "6. Fit to data\nIf the model has passed all the convergence checks, you need to check if the model fits well with the data, which will help determine if the model structure is correct. Model can compile, run, and pass convergence tests even if the model structure is incorrect."
  },
  {
    "objectID": "num_meths/TMB_convergence.html#link-to-r-function",
    "href": "num_meths/TMB_convergence.html#link-to-r-function",
    "title": "TMB Model Convergence",
    "section": "Link to R function",
    "text": "Link to R function\nI have a R function that does these checks for a RTMB model with the objective function and optimizer output (from nlminb). This does not check the standard deviations or fit the model results to data: check_RTMB_model"
  },
  {
    "objectID": "stock_assess/optimization_hcr.html",
    "href": "stock_assess/optimization_hcr.html",
    "title": "Ecological optimization: i.e., harvest control rules 101",
    "section": "",
    "text": "Optimization methods are used to find the best fishing strategy given 1) specified objective, 2) a model of stock dynamics, and 3) specified management alternatives."
  },
  {
    "objectID": "stock_assess/stock_assess_home.html",
    "href": "stock_assess/stock_assess_home.html",
    "title": "Stock Assesssment Notes",
    "section": "",
    "text": "Topic\nSub-topic\nNotes\nCode\n\n\n\n\nRecruitment\nUnderstanding Stock Recruitment\n📖\n🖥️\n\n\n\nEquilibrium Recruitment\n📖\n🖥️\n\n\n\n\n📖\n🖥️"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantitative Fisheries Notes",
    "section": "",
    "text": "test"
  }
]